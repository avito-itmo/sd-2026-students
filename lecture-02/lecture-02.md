# Системное проектирование

# Лекция 2. Архитектурные стили и паттерны проектирования

**Длительность:** 90 минут<br>
**Версия:** 1.1 (февраль 2026)

---

## Цели и ожидаемые результаты

После лекции студент должен знать:

- Основные архитектурные стили: Монолит и Микросервисы. Их плюсы и минусы.
- Типовые архитектурные фреймворки: Многослойная, Гексогональная и Луковичная Архитектура. Их основные отличия друг от друга.
- Паттерны распределенных систем: Сага, CQRS, Event Sourcing.

---

## Предпосылки

- Лекция 1: "Введение в системное проектирование".

## План и тайминг

1. **Архитектурные стили**: монолит (15 мин), микросервисы (20 мин), event‑driven (10 мин)
2. **Архитектурные каркасы**: Layered / Hexagonal / Onion (15 мин)
3. **Паттерны сложных взаимодействий**: CQRS, Saga, Event Sourcing (20 мин)
5. **Вопросы и обсуждение** (10 мин)

---

# Темы лекции

## Архитектурные стили: формы организации систем

### Монолит

Монолитная архитектура - это единый развёртываемый артефакт, внутри которого живут все основные части системы. Важно понимать, что монолит вовсе не равен "комку грязи". Хорошо спроектированный монолит может быть строгим, модульным и дисциплинированным. Он позволяет быстро запускать продукт, поддерживать высокую скорость сквозных изменений и сохранять сильную транзакционную целостность данных. На ранних этапах развития, когда границы доменов ещё неустойчивы, а инфраструктуру строить "с запасом" преждевременно, монолит даёт отличное соотношение скорости и управляемости.

Монолит уместен, когда команда небольшая или средняя, требования меняются часто, а большая доля бизнес‑операций требует строгих ACID‑гарантий. Когда нет явных, слабо связанных подсистем, которые нужно масштабировать независимо или когда необходимо быстро экспериментировать с функциональностью и выпускать сквозные изменения одним релизом, не координируя десятки сервисов. И, наконец, когда ценится простота эксплуатации: один артефакт, понятный пайплайн поставки, единая наблюдаемость.

В крупных Монолитах можно встретить его вариацию - Модульный Монолит (иногда встречается название Модулит). В этом подходе, различные части, чаще всего "ограниченные контексты", выносят в отдельные Модули. Модуль полностью решает отдельную бизнес-задачу, в этом отношении он соответствует принципу SRP из SOLID. Модуль имеет API для взаимодействия с другими модулями. API модулей формируют четкие границы ответсвенности между Модулями. Взаимодействие между модулями может быть синхронным, через обычные вызовы методов/функций, либо асинхронным - через внутреннюю шину событий. Модульный Монолит это своего рода смесь Монолита и Микросервисов и иногда Модули могут быть вынесены в отдельные самостоятельные сервисы.

Дизайн модульного монолита начинается с декомпозиции по доменам (DDD): крупные области - "Заказы", "Биллинг", "Каталог" - оформляются в модули с чёткими границами. У каждого модуля - свой публичный фасад (application service), а внутренние пакеты скрыты; прямые обращения к данным "чужого" модуля запрещены. Зависимости направлены сверху вниз: пользовательский интерфейс обращается к приложениям, те - к доменам, а домены - к инфраструктуре. Архитектурные инварианты фиксируют правила доступа к данным. Для синхронности эволюции модулей полезны внутрипроцессные доменные события: модуль публикует событие в шину памяти, другие модули реагируют асинхронно, не вводя жёстких связей.

Если в будущем потребуется выносить Модули в отдельные сервисы, то модульные границы и событийная интеграция облегчат миграцию по паттерну *Strangler*.

#### Паттерны в Монолите

Набор паттернов в монолите опирается на классические архитектурные фреймворки. Трёхслойная архитектура - удерживает зависимости простыми и предсказуемыми. Гексагональная архитектура отделяет доменную логику от внешних интерфейсов - именно это облегчает как тестирование, так и возможный вынос модуля в отдельный сервис в будущем. Луковичная архитектура развивает идею направленности зависимостей к центру - домену. На уровне разделения кода разумно практиковать *package‑by‑feature* (группировка по функциональности), а не только *package‑by‑layer*: так меньше пересечений при изменениях. Простые CRUD‑сценарии выгодно реализовывать паттерном *Transaction Script*, а там, где много инвариантов и правил, - через богатый *Domain Model*. Широко применяются Repository, Unit of Work, Application Service, Facade. Для интеграций наружу удобен связанный подход: *in‑process* event bus + Transactional Outbox, из которого фоновый воркер надёжно публикует события во внешние очереди.

#### Транзакции

Работа с транзакциями в монолите проще, потому что всё происходит в пределах одной БД/шарда. Граница транзакции совпадает с границей сценария использования: приложение открывает транзакцию, модифицирует агрегаты, фиксирует доменные события в outbox и коммитит. Для конкурентного доступа выбирают подходящий инструмент: оптимистические версии записей там, где конфликты редки, пессимистические блокировки (select for update) - там, где вероятность конкурентного доступа невысокая. В целях оптимизации можно подобрать подходящий уровень изоляции БД. Если в бизнес-логике есть долгоживущие операции, то их не оформляют в одну транзакцию, а разбивают на шаги и связывают асинхронно. Идемпотентность обеспечивают ключами/версиями и проверками повторов. В мире микросервисов такие сценарии потребовали бы распределенных транзакций (которые мы расмотрим позже), а в монолите - это локальные ACID‑операции с явной фиксацией инвариантов.

#### Плюсы и Минусы

Сильные стороны монолита - высокая скорость разработки и отладки, простые транзакции, единая наблюдаемость и меньше инфраструктурных артефактов. Слабые - риск "big ball of mud" при потере дисциплины, общая БД как узкое место, удлиняющиеся сборки и релизы по мере роста кода, трудности точечного масштабирования "горячих" участков и возрастающие координационные издержки для больших команд. Эти минусы, однако, управляемы архитектурной практикой и автоматическими проверками.

Типичные сбои хорошо известны: "God‑классы" и перегруженные модули, циклические зависимости,  прямой доступ к таблицам "чужих" модулей; длинные транзакции, ведущие к блокировкам и эскалациям; скрытые кросс‑модульные связи. Диагностика опирается на APM‑трейсинг внутри процесса, профилировщики БД и чёрные списки зависимостей, которые контролируются на CI.

### Микросервисная архитектура

Микросервисы - это способ строить систему как набор небольших, слабо связанных сервисов, каждый из которых отвечает за небольшой бизнес‑кейс и развёртывается независимо. Ключевая идея - заменить крупные межмодульные связи внутри одного процесса на чёткие контракты между процессами: синхронные API и асинхронные события. Такой стиль предъявляет высокие требования к дисциплине разработки и к платформе: автоматизация сборки и поставки (CI\CD), логгирование, мониторинг.

Этот подход уместен, когда у продукта есть естественные границы доменов, и каждая команда может развивать "свой кусок" с минимальным пересечением. Микросервисы хорошо работают, если требуется по‑разному масштабировать части системы: где‑то критичны операции записи, где‑то - чтения и кэширование, а где‑то упор на CPU/GPU‑интенсивные вычисления. Отдельная мотивация - изоляция отказов и рисков: регуляторные требования, разные SLA и политики безопасности по сегментам. Так же, микросервисы оправданы, если важна технологическая автономия команд: различные языки/стеки и уже существует зрелая платформа для эксплуатации.

#### Паттерны

На практике для определения границ сервисов берут идеи DDD: сервис - это бизнес‑возможность (capability) в пределах ограниченного контекста. Контракты формализуют двумя каналами: синхронные API (HTTP/gRPC) и асинхронные события (Kafka/RabbitMQ). Контракты версионируют и сохраняют обратную совместимость. Для проверки интеграций используют consumer‑driven contracts (например, Pact), чтобы изменения провайдера не ломали потребителей. Коммуникации подбирают по характеру задач: запрос‑ответ для быстрых и критичных операций; события и очереди - для интеграций и согласования между контекстами. На периметре располагают API‑шлюз, который занимается маршрутизацией, аутентификацией, лимитированием и т.д. Каждый сервис владеет своей схемой и не делится общей БД, данный подход называется Database per Service.

Микросервисы общаются друг с другом по сети. Т.к. сеть это ненадёжная среда (по сравнению с in-process вызовами), отказоустойчивость приходится поддерживать типовыми паттернами: ограничение времени ожидания и повтор с экспоненциальной паузой, предохранитель (circuit breaker), изоляция по отсекам (bulkhead), а также ограничение скорости. Там, где это уместно, применяют кэширование и разделение чтения/записи (CQRS), чтобы разгрузить "горячие" пути. Сервис‑дискавери позволяет динамически находить экземпляры, а регулярные health‑checks - быстро выводить из ротации неисправные инстансы.

Есть и характерные анти‑паттерны. Самый известный - распределённый монолит: сервисы тесно зависят друг от друга синхронными вызовами, из‑за чего релиз приходится делать синхронно всем сервисам, а отказ одного узла приводит к каскадным отказам остальных частей системы. Опасна и общая БД между сервисами: так теряется независимость и усложняется эволюция. Ещё риск - "болтливость по сети", когда для одного пользовательского действия требуется десятки запросов между сервисами. Наконец, гипер‑декомпозиция порождает сотни слишком мелких сервисов и взрыв операционной сложности без реальной выгоды.

#### Транзакции

Согласованность и транзакции в распределённой системе решают без глобальных ACID. Для распределенных транзакций чаще всего применяют саги - долгоживущие бизнес‑транзакции, состоящие из цепочки локальных шагов и компенсирующих действий. Реже применюят двухфазный коммит. Ближе к концу лекции мы рассмотрим этим паттерны подробнее.
Чтобы события не терялись и не дублировались, используют связку outbox/inbox: запись доменного события фиксируют в таблице Outbox в одной транзакции с изменениями модели, а фоновый процесс надёжно публикует его наружу. Для гарантированной однократной обработки сообщений на стороне потребителей выбирают семантку At Least Once + идемпотентность. Для обратимости бизнес‑действий заранее проектируют компенсации и таймауты.

#### Плюсы и Минусы

Компромиссы микросервисов прозрачны. Их сильные стороны - независимые релизы, изоляция отказов, гибкое масштабирование и технологическая автономия команд. Цена - рост операционной сложности и стоимости платформы, задержки и ненадёжность сети, сложность согласования данных и более высокие требования к культуре DevOps/SRE. Если команда и платформа готовы - выигрыши ощутимы; если нет - риски превышают пользу.

### Event-driven (событийная архитектура)

Событийная архитектура строит систему вокруг "фактов, которые произошли". Компоненты публикуют неизменяемые события - компактные описания свершившихся фактов, в брокер сообщений, а другие компоненты на них реагируют. Отправитель не знает своих получателей, связь ослаблена во времени (асинхронность) и по месту (через шину), что резко снижает связность и облегчает эволюцию. Важно различать **команды** ("сделай") и **события** ("случилось"): команды адресные и синхроннее по смыслу, события - факт и широковещательны по природе.

Где это уместно. Event‑driven полезна там, где много независимых реакций на один факт (фан‑аут), где критична эластичность под пики и буферизация нагрузки, где требуется near‑real‑time аналитика и автоматизация бизнес‑процессов. Она хорошо сочетается с микросервисами, но не менее полезна и внутри модульного монолита (внутрипроцессные доменные события), позволяя отделять реакции без жёстких вызовов.

Строительные блоки. Паблишеры и консьюмеры общаются через брокер (Kafka, RabbitMQ). Организация потоков включает **топики/очереди**, **партиции** для горизонтального масштабирования и **consumer‑группы** для параллельной обработки. Подбираем **семантику доставки**: на практике доминирует *at‑least‑once* с идемпотентными обработчиками, *at‑most‑once* допустима для не критичных сценариев. Схемы событий описывают JSON/Avro/Protobuf и хранят в Schema Registry. Эволюция делается через обратную/прямую совместимость и версионирование полей, а не "ломающие" изменения.

Типичные ошибки. Слишком "толстые" события (утечка доменной логики в сообщения) приводят к скрытой связности; смешение команд и событий ломает модель; отсутствие версионирования и контрактов к событию ломает совместимость. Ставка на глобальный порядок по всему домену блокирует масштабирование; попытки воссоздать строгую транзакционность поверх событий приводят к хрупкости.

---

## Архитектурные фреймворки приложения

Фреймворки задают правила **зависимостей** и **границ** между слоями приложения. Их цель - удерживать доменную логику независимой от библиотек/БД и упростить тестирование, сопровождение и возможную эволюцию архитектуры.

### Layered (многослойная) архитектура

Классическая структура: `Presentation + Application + Data`. Зависимости направлены сверху вниз: экран/маршрутизация и контроллеры (Presentation) обращаются к прикладному слою (Application), а тот - к слою данных (Data). Каждый слой знает только о слое под собой, что позволяет менять интерфейс независимо от бизнес‑логики, а бизнес‑логику - независимо от конкретной технологии хранения.

Presentation не содержит бизнес‑правил и не обращается к Data напрямую. Application не "протекает" UI‑зависимостями. Data скрывает детали ORM/SQL за репозиториями и не тянет доменные политики.

#### Роли слоёв

- **UI** - контроллеры/хэндлеры, валидация ввода, преобразование в команды.
- **Application** - сущности, агрегаты, value‑объекты, доменные сервисы и инварианты. Use‑cases, транзакционные границы, координация доменных операций, публикация событий (outbox).
- **Infrastructure** - ORM/БД, брокеры, файловые/сетевые адаптеры, внешние API.

**n‑layer (2->5 слоёв): как наращивание слоёв усиливает разделение обязанностей**. Многослойная (n‑layer) архитектура делит приложение на логические слои, каждый из которых отвечает за свой аспект. Добавление слоя - это осознанное усиление разделения и изоляции изменений.

- **2‑layer (Presentation + Data).** Интерфейс приложения общается напрямую с хранилищем. Бизнес‑правила в такой схеме часто оказываются либо **в БД** (триггеры, хранимые процедуры, чек‑констрейнты), либо **в слое представления** (контроллеры/формы). Подход уместен, когда бизнес‑логики немного и она сравнительно стабильна. Иначе быстро возникает плотная связность UI и данных.
- **3‑layer (Presentation + Application + Data).** Классическая веб‑модель. **Presentation** - отображает данные и собирает ввод. **Application** - обрабатывает запросы и применяет бизнес‑правила. **Data** - управляет хранением (БД/файлы/внешние сервисы). Разделение интерфейса и логики делает систему управляемее и масштабируемее.
- **4‑layer (Presentation + Application + Domain + Data).** Здесь мы выделяем из слоя Application отдельный Domain слой. Domain - это суть бизнеса (правила, инварианты, модель). Application - это оркестратор сценариев (что, в каком порядке, в каких границах транзакций и с какими внешними эффектами). Такое разделение позволяет оставлять бизнес-модель чистой и стабильной, а сценарии/интеграции менять свободно. Domain формулирует правила: "скидка не больше X", "баланс не уходит в минус". Application решает "сначала проверить лимит, затем изменить агрегат, сохранить, опубликовать событие, отправить письмо".
- **5‑layer (Presentation + Application + Domain + Persistence + Infrastructure).** это не стандарт, а несколько популярных вариаций поверх схемы Presentation + Application + Domain + Infrastructure. Чаще всего пятым слоем выделяют Data/Persistence (отдельно от Infrastructure). Persistence - репозитории, unit of work, маппинг домена ↔ модели хранения, запросы/спеки. Infrastructure - "остальная машинерия": очереди, мейлеры, внешние API, кэш, телеметрия, секреты.

Практический смысл наращивания слоёв - упростить развитие и замену отдельных частей без каскадных изменений: менять UI, не трогая бизнес‑правила; эволюционировать бизнес‑логику, не переписывая доступ к данным; вводить кэш/безопасность и интеграции на границе, не перегружая приложение.

### Hexagonal (Ports & Adapters)

Идея подхода в том, что бы отделить Ядро приложения от внешнего мира и развивать бизнес-правила без привязки к внешним зависимостям. Для этого домен изолируют "портами" - абстракциями входа/выхода; конкретные технологии - "адаптеры", подключаемые к портам. Есть **входные порты** (команды/запросы из UI/HTTP/CLI/queue) и **выходные порты** (репозитории, внешние сервисы, брокеры).

**Структура.** `Drivers (UI/CLI/Queue) → Inbound Adapters → Application (Use‑Cases) → Domain ← Outbound Ports ← Outbound Adapters (DB/HTTP/Kafka)`.

**Сильные стороны.** Доменная логика и use‑cases не зависят от фреймворков; легко подменять адаптеры в тестах; упрощает постепенную миграцию (например, смену БД/транспорта).
**Риски.** Рост количества интерфейсов/адаптеров; избыточная абстракция в малых проектах; иногда бизнес‑логика протекает в адаптеры.

**Когда выбирать.** Нужна технологическая независимость, несколько интерфейсов входа (HTTP + очередь + CLI), активное тестирование use‑cases без инфраструктуры.

### Onion (луковичная)

Концентрические слои с **правилом зависимостей**: все зависимости направлены **к центру** (домену). От внешнего круга к внутреннему: `Infrastructure → Application → Domain`. Домен - первичен и не зависит от внешних библиотек.

**Особенности.** Чёткое разделение Доменной логики и Инфраструктурной логики. Сильный акцент на неизменность домена при смене технологий. Часто реализуется совместно с портами/адаптерами.

**Сильные стороны.** Максимальная устойчивость домена к технологическим изменениям; ясные границы; удобные юнит‑тесты доменной логики.

**Риски.** Более высокий входной порог. Больше boilerplate-кода. Соблазн чрезмерной абстракции.

### Вопросы

- В чем вы видите сходство Гексагональной и Луковичной архитектур?
- В чем вы видите их различие?

### Сопоставление Onion и Hexagonal

Обе модели решают близкую задачу - изоляцию домена от технологий, но делают это разными акцентами и хорошо сочетаются.

- Onion - направление зависимостей: все стрелки идут к центру (домену). Слои внешнего круга (инфраструктура) не "протекают" внутрь; доменная модель не знает ни о БД, ни о веб‑фреймворке. Этот подход удобен, когда главное - защитить доменные политики от технологических решений и упростить unit‑тестирование ядра.
- Hexagonal - формализация границ через **порты** (интерфейсы) и **адаптеры** (конкретные реализации). Это удобно, когда требуется несколько вариантов входа (HTTP, очередь, CLI) или выхода (разные БД/шины), а также когда вы хотите строго фиксировать контракты для подмены на тестах и при миграциях.
- Частая практика - "луковица с портами": домен и прикладной слой образуют внутренние круги (Onion), а границы между ними и внешним миром оформляются портами/адаптерами (Hexagonal). Порты объявляются во внутренних слоях, адаптеры живут снаружи.

---

## Архитектурные паттерны

### Паттерны сложных взаимодействий: CQRS, Saga, Event Sourcing

Эти паттерны помогают управлять сложными потоками данных и обеспечить согласованность в масштабируемых системах (как монолитах, так и микросервисах).

#### Saga (долгоживущие бизнес‑транзакции)

Согласно CAP-теореме, в распределенной системе мы не можем достичь одновременно: строгой согласованности, высокой доступности и устойчивости к разделению. В связи с этим, создание полноценных ACID-транзакций является архитектурной проблемой. На практике применяют два паттерна: 2 Phase Commit и Saga.

Сага является практически более распространненым паттерном, поэтому рассмотрим только его. Сага отказывается от Строгой Согласованности и использует подход Согласованность в конечном счёте. Одна большая логическая транзакция разбивается на отдельные шаги - Фазы. Каждую Фазу выполняет отдельный микросервис. В результате выполнения Фазы, микросервис фиксирует у себя необходимые изменения в рамках своей локальной транзакции. Далее управление передается следющему сервису. При успешном выполнении всех Фаз, Сага считается успешно выполненной, а в случае сбоя на одной из Фаз, происходит обратный откат выполненных Фаз на предыдущих шагах. Эти откаты называют Компенсациями. У каждой Фазы должен быть код, который её выполняет, а так же код, который её откатывает.

Для синхронизации Фаз в рамках Саги используют два стиля: **оркестрация** (центральный координатор) и **хореография** (реакции на события). Оркестрация проще для восприятия - есть отдельный сервис, который следит за выполнением каждой фазы и при успешном заврешении одной Фазы, запускает следующую. А случае сбоя, откатывает уже выполненные транзакции. Часто реализуется как конечный автомат. Но несмотря на его простоту он обладает существенным недостатком. Он становится единой точкой отказа всех бизнес-транзакций. 

В качестве альтернативы Оркестрации применяется Хореография. В этом подходе, сервисы самостоятельно управляют выполнением общей транзакции. Когда заканчивается одна Фаза сервис, выполнивший эту Фазу, публикует событие об успешном выполнении (это может быть доменное событие). На это событие подписан следующий обработчик и она начинает выполнение своей Фазы. Если одна из Фаз заканчивается неуспехом, то об этом также публикуется событие, что бы сервисы могли отрегировать на него и откатить свои Фазы. Система спроектированная таким образом более устойчива, но т.к. транзакции нигде не хранятся централизованно, то становится сложным определить в каком состоянии находятся транзакции.

**Ключевые элементы.**

- Описание шагов и чёткие **компенсирующие действия**; **таймауты** и политика повторов.
- **Корреляция** (trace/correlation‑id), идемпотентность, outbox/inbox.
- Часто оформляется как **конечный автомат** (state machine) в оркестраторе.

**Риски.** Сложность наблюдаемости; ошибка в компенсации ведёт к рассинхрону; рост количества событий.

#### CQRS (Command–Query Responsibility Segregation)

При высокой доли чтений и разнообразных представлений данных, бывает полезным разделить операции записи (commands) и чтения (queries) на разные модели и, при необходимости, разные хранилища. На слайдах видно, что при выполнении Команд мы обращаемся к Домену, а при выполнении Запросов идём напрямую в хранилище. Это может показаться странным и небезопасным, что мы предоставляем практически прямой доступ к БД. Но в этом нет проблем. Вызов Домена для Команд обусловлен тем, что при изменении данных нам важно следить за сохранением инвариантов, но когда мы читаем данные из БД, мы ничего не можем изменить, а следовательно, не можем нарушить инварианты. Получается, мы можем пропустить слой Домена и отдать даныне напрямую. Единственное, что формат хранения данных и формат ответа скорее всего не будут совпадать. Для этого на уровне БД реализуют проекции данных и денормализацию. В некоторых случаях это может быть совершенно другая БД, которая синхронизируется с основной БД и лучше заточена под выборки данных.

**Ключевые элементы.**

- Write‑side: агрегаты/инварианты, транзакционные команды.
- Read‑side: **проекции/материализованные представления**, обновляемые из потока изменений.
- Канал синхронизации: доменные события или CDC из БД.
- API: явное разделение эндпоинтов на commands и queries.

**Риски.** Дублирование моделей, **eventual consistency** между сторонами, рост операционной сложности. Не стоит применять для простого CRUD.

#### Event Sourcing

Event Sourcing - это подход, где источником истины считается не текущее состояние объекта, а журнал событий (append-only), фиксирующий все изменения как последовательность фактов "что произошло". Каждое новое изменение записывается как неизменяемое событие, а текущее состояние восстанавливается "проигрыванием" (replay) этих событий. Чтобы восстановление не было слишком дорогим, используют снапшоты и/или заранее построенные проекции для чтения.
Плюсы: сильный аудит и трассируемость, возможность "машины времени" (восстановить состояние на дату, пересчитать проекции, симулировать альтернативы).
Минусы: усложняется модель (версионирование событий, миграции схем, согласованность проекций, идемпотентность обработчиков) и растёт цена эксплуатации.

**Ключевые элементы.**

- **Event Store** (append‑only) с версионированием и метаданными.
- **События неизменяемы** эволюцию схемы решают версионированием/апсерт‑конвертерами.
- **Снапшоты** для ускорения восстановления; **проекции** для чтения.

#### Вопросы

1. Как обеспечить **идемпотентность** потребителя событий? Что хранить (ключи/версии/журналы), где хранить и как чистить.

---

# Контрольные вопросы

1. В чем плюсы и минусы Монолита?
2. В чем плюсы и минусы Микросервисов?
